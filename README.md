# Pipeline de Dados: Mobilidade Urbana PBH

Projeto de engenharia de dados para aplicar ETL, arquitetura medallion, data lake e data warehouse usando dados p√∫blicos sobre a mobilidade urbana de Belo Horizonte (PBH), MG

# Instru√ß√µes de execu√ß√£o

## Requerimentos:

- python 3.8.10
- WSL: 2.6.3.0
- Homebrew 5.0.14

## Setup de ambiente

Instalar databricks-cli: `brew instal databricks`

Instalar o python venv:
```
sudo apt-get update
sudo apt install python3.8-venv  openjdk-17-jdk
```

Criar e ativar o ambiente virutal: 
```
python3 -m venv venv
source ./venv/bin/activate
python3 -m pip install --upgrade pip setuptools
pip install -r requirements.txt
```

Configurar databricks CLI:
```
databricks configure --host https://{seu-host}.cloud.databricks.com --token {seu personal access token}
```

## Testes

Executar comando: `pytest`

## Execu√ß√£o do workflow

Executar databricks bundle:
```
databricks bundle deploy --target dev
databricks bundle run mobilidade_urbana_pipeline
```

## Verificando funcionamento

Ap√≥s fazer o deploy do workflow (`databricks bundle deploy --target dev`) verifique se subiu corretamente com `databricks bundle summary --target dev`
![alt text](docs/images/bundle_summary.png)

No menu jobs & pipelines verifique a execu√ß√£o correta da pipeline
![alt text](docs/images/job_success.png)

Verifique as tabelas no banco fazendo uma consulta SQL `SELECT * FROM mobilidade_urbana.gold.gold_viagens`
![alt text](docs/images/sql_query.png)

# Vis√£o Geral

Este reposit√≥rio cont√©m um pipeline completo de dados que:

- Extrai dados p√∫blicos da API CKAN dos dados de mobilidade urbana
- Constr√≥i camadas Bronze ‚Üí Silver ‚Üí Gold (arquitetura medallion)
- Armazena resultados em tabelas Delta hospedadas no Databricks
- Facilita an√°lises e visualiza√ß√µes posteriores

# Arquitetura                                                                                                     
                                                            
```mermaid                                                                                                         
flowchart TB                                              
    subgraph Extra√ß√£o
        API[API CKAN\ndados.pbh.gov.br] -->|package_show\ndescoberta din√¢mica| SCRIPT[extrair_dados_PBH.py]
        SCRIPT -->|download CSV| RAW["/Volumes/.../raw_data\nüìÅ CSV"]
    end

    subgraph Bronze
        RAW -->|read CSV + ingestion_timestamp| BRZ["/Volumes/.../bronze/mco\nüì¶ Parquet ¬∑ append"]
    end

    subgraph Silver
        BRZ -->|parse datas ¬∑ cast tipos\ndedup ¬∑ normalize colunas| SLV["silver.mco\nüíé Delta ¬∑ overwrite"]
    end

    subgraph Gold
        SLV --> GV["gold_viagens\nviagens ¬∑ ve√≠culos ¬∑ passageiros\nfaturamento estimado"]
        SLV --> GO["gold_ocorrencias\ninterrup√ß√µes ¬∑ falhas mec√¢nicas\neventos inseguros"]
        SLV --> GT["gold_tipo_dia\nm√©tricas por tipo de dia\n√ó linha"]
        SLV --> DIM1["dim_tipo_dia\n34 tipos de dia"]
        SLV --> DIM2["dim_ocorrencia\n18 c√≥digos de evento"]
    end

    subgraph Orquestra√ß√£o
        DAB["Databricks Asset Bundles\npipeline_job.yml"] -.->|task dependencies| SCRIPT
        DAB -.-> BRZ
        DAB -.-> SLV
        DAB -.-> GV
    end

    style API fill:#4a9eff,color:#fff
    style BRZ fill:#cd7f32,color:#fff
    style SLV fill:#c0c0c0,color:#000
    style GV fill:#ffd700,color:#000
    style GO fill:#ffd700,color:#000
    style GT fill:#ffd700,color:#000
    style DIM1 fill:#ffd700,color:#000
    style DIM2 fill:#ffd700,color:#000
```

# Detalhamento das etapas

- Extra√ß√£o inicial:
O script utils/extrair_dados_PBH.py √© respons√°vel pela extra√ß√£o automatizada dos dados diretamente do portal de dados abertos da Prefeitura de Belo Horizonte (PBH), utilizando a API CKAN para descoberta dos recursos dispon√≠veis.

O processo realiza o download dos arquivos no formato CSV e os armazena em volumes dentro do schema raw_data, compondo a camada Raw do pipeline.

Embora a API CKAN disponibilize endpoints que retornam os dados diretamente na response (formato JSON), essa abordagem possui uma limita√ß√£o de aproximadamente 192 mil registros por requisi√ß√£o. Considerando o volume de dados do projeto, optou-se pelo download direto dos arquivos CSV completos, garantindo maior confiabilidade, escalabilidade e integridade dos dados ‚Äî sem abrir m√£o da automa√ß√£o do processo.

Essa estrat√©gia evita truncamentos, reduz riscos de inconsist√™ncia e torna o pipeline mais robusto para cargas hist√≥ricas e futuras expans√µes.

- Camada Bronze: 
O script bronze/load_bronze_layer.py acessa os arquivos armazenados no schema raw_data e os grava no schema bronze no formato Parquet. Nesta etapa, os dados s√£o mantidos o mais pr√≥ximo poss√≠vel da origem, com poucas transforma√ß√µes aplicadas. O principal objetivo √© estruturar os arquivos brutos em um formato otimizado para processamento distribu√≠do, al√©m de adicionar a coluna ingestion_timestamp, que permite rastreabilidade e controle de qualidade das cargas. A escrita √© feita no modo append, garantindo que novas execu√ß√µes do pipeline n√£o sobrescrevam dados hist√≥ricos.

- Camada Silver
Na camada Silver, os dados provenientes da Bronze s√£o carregados e transformados. Como a origem j√° apresenta boa qualidade estrutural, n√£o h√° necessidade de transforma√ß√µes complexas. O foco do script est√° em ajustes de schema, como convers√µes de tipos para date, timestamp e integer, remo√ß√£o de colunas vazias, padroniza√ß√£o de nomes, deduplica√ß√£o de registros e pequenos ajustes de legibilidade. Os dados s√£o salvos no formato Delta utilizando o modo overwrite, garantindo integridade de schema, consist√™ncia transacional e versionamento autom√°tico.

- Camada Gold
Nesta camada, os dados da Silver s√£o organizados de forma orientada ao neg√≥cio. Foram criadas tr√™s tabelas fato. 
    - gold_viagen: Consolida m√©tricas relacionadas √†s viagens, com granularidade por data, linha e sublinha, incluindo indicadores como quantidade de viagens, ve√≠culos distintos, dist√¢ncia percorrida, passageiros transportados e faturamento estimado. 
    - gold_ocorrencias: √â voltada para an√°lises de interrup√ß√µes operacionais, trazendo m√©tricas relacionadas √†s poss√≠veis ocorr√™ncias que impedem ou interrompem viagens, com granularidade por data, linha, ocorr√™ncia e justificativa, considerando apenas registros onde houve algum evento. 
    - gold_tipo_dia: Possui estrutura semelhante √† gold_viagens, por√©m com granularidade por tipo de dia e linha, permitindo an√°lises comparativas do uso do transporte p√∫blico entre dias √∫teis, s√°bados e domingos/feriados, sem aumentar excessivamente o volume e a granularidade da tabela principal de viagens.
    - dim_ocorrencia: tabela dimens√£o criada usando script e que possui as descri√ß√≤es detalhadas para as justificativas de ocorrencias.
    - dim_tipo_dia: tabela com o descritivo dos tipos de dias referenciados na tabela gold_tipo_dia.
    As tabelas de dimens√£o podem ser conectada √† tabelas gold_ocorrencia em queries e dashboards, melhorando a legibilidades das an√°lises. Estas foram criadas via script pois n√£o foram disponibilizadas como csv pela PBH, estando presentes apenas em um PDF descritivo das tabelas.